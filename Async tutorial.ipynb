{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "585ff7bb-aadb-4abd-82fe-d0c53200c23e",
   "metadata": {},
   "source": [
    "Base code obtained from https://realpython.com/async-io-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c28768-3027-4696-b526-bc12f3c376c3",
   "metadata": {},
   "source": [
    "# The *asyncio* package and *async/awat*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4e102a-1b52-40d7-806c-80ff6acb4136",
   "metadata": {},
   "source": [
    "## The *async/await* syntax and native coroutines\n",
    "\n",
    "A coroutine is a function that **can suspend its execution before reaching return**, and can indirectly pass control to another coroutine for some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ffecc6a-10ec-4c7d-9217-e90a2aeb8b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import time\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "import itertools as it\n",
    "import argparse\n",
    "\n",
    "# This allows to run asyncio on a Jupyter Notebook\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a45406c4-523c-43ac-9cac-d8456fec27b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def count():\n",
    "    print(\"One\")\n",
    "    await asyncio.sleep(1)\n",
    "    print(\"Two\")\n",
    "\n",
    "async def main():\n",
    "    await asyncio.gather(count(), count(), count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b13360b-e7ad-4382-be9b-53048a9f411c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One\n",
      "One\n",
      "One\n",
      "Two\n",
      "Two\n",
      "Two\n",
      "Async code executed in 1.05 seconds.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    s = time.perf_counter()\n",
    "    asyncio.run(main())\n",
    "    elapsed = time.perf_counter() - s\n",
    "    print(f\"Async code executed in {elapsed:0.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1275d654-7e36-46f5-b839-e55c170b5525",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count():\n",
    "    print(\"One\")\n",
    "    time.sleep(1)\n",
    "    print(\"Two\")\n",
    "\n",
    "def main():\n",
    "    for _ in range(3):\n",
    "        count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fac89946-4348-421c-ba41-2e284d57dacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One\n",
      "Two\n",
      "One\n",
      "Two\n",
      "One\n",
      "Two\n",
      "Synchronous code executed in 3.01 seconds.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    s = time.perf_counter()\n",
    "    main()\n",
    "    elapsed = time.perf_counter() - s\n",
    "    print(f\"Synchronous code executed in {elapsed:0.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49854f01-33e5-434b-8933-6e51829bc393",
   "metadata": {},
   "source": [
    "## The rules of *asyncio*\n",
    "\n",
    "The keyword ***await* passes function control back to the event loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4595100a-62f5-4c7a-9f82-17e9b82ad85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def g():\n",
    "    # Pause here and come back to g() when f() is ready\n",
    "    r = await f()\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba1355ce-7d10-4a3e-be16-db0a01ee452f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSI colors\n",
    "c = (\"\\033[0m\", #End of color\n",
    "     \"\\033[36m\", #Cyan\n",
    "     \"\\033[91m\", #Red\n",
    "     \"\\033[35m\") #Magenta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fc19670-3ee7-4c8b-b754-d095c167034a",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def makerandom(idx: int,\n",
    "                     threshold: int = 6) -> int:\n",
    "    print(c[idx + 1] + f\"Initiated makerandom({idx}) with threshold {threshold}.\")\n",
    "    i = random.randint(0, 10)\n",
    "\n",
    "    while i <= threshold:\n",
    "        print(c[idx + 1] + f\"makerandom({idx}) == {i} too low; retrying...\")\n",
    "        await asyncio.sleep(idx + 1)\n",
    "        i = random.randint(0, 10)\n",
    "\n",
    "    print(c[idx + 1] + f\"---> Finished: makerandom({idx}) == {i}\" + c[0])\n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23ac664e-3e59-450b-9890-74dbf752af6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    res = await asyncio.gather(*(makerandom(i, 10-i-1) for i in range(3)))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "233aa6b4-c665-4fa4-80da-72d95c7b3068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mInitiated makerandom(0) with threshold 9.\n",
      "\u001b[36mmakerandom(0) == 4 too low; retrying...\n",
      "\u001b[91mInitiated makerandom(1) with threshold 8.\n",
      "\u001b[91mmakerandom(1) == 4 too low; retrying...\n",
      "\u001b[35mInitiated makerandom(2) with threshold 7.\n",
      "\u001b[35mmakerandom(2) == 0 too low; retrying...\n",
      "\u001b[36mmakerandom(0) == 4 too low; retrying...\n",
      "\u001b[91mmakerandom(1) == 7 too low; retrying...\n",
      "\u001b[36mmakerandom(0) == 4 too low; retrying...\n",
      "\u001b[35mmakerandom(2) == 4 too low; retrying...\n",
      "\u001b[36mmakerandom(0) == 8 too low; retrying...\n",
      "\u001b[91m---> Finished: makerandom(1) == 10\u001b[0m\n",
      "\u001b[36mmakerandom(0) == 7 too low; retrying...\n",
      "\u001b[36mmakerandom(0) == 8 too low; retrying...\n",
      "\u001b[35mmakerandom(2) == 4 too low; retrying...\n",
      "\u001b[36mmakerandom(0) == 7 too low; retrying...\n",
      "\u001b[36mmakerandom(0) == 1 too low; retrying...\n",
      "\u001b[36mmakerandom(0) == 6 too low; retrying...\n",
      "\u001b[35m---> Finished: makerandom(2) == 9\u001b[0m\n",
      "\u001b[36mmakerandom(0) == 3 too low; retrying...\n",
      "\u001b[36mmakerandom(0) == 9 too low; retrying...\n",
      "\u001b[36mmakerandom(0) == 7 too low; retrying...\n",
      "\u001b[36m---> Finished: makerandom(0) == 10\u001b[0m\n",
      "\n",
      "r1: 10, r2: 10, r3: 9\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    random.seed(444)\n",
    "\n",
    "    loop = asyncio.get_event_loop()\n",
    "    r1, r2, r3 = asyncio.run(main())\n",
    "    print()\n",
    "    print(f\"r1: {r1}, r2: {r2}, r3: {r3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef988e6-9b9c-4f52-aa59-0fcbaf147f3f",
   "metadata": {},
   "source": [
    "# *Async IO* Design Patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dd6ae8-fd87-4b3c-bd9b-a46366bc0d3e",
   "metadata": {},
   "source": [
    "## Chaining coroutines\n",
    "\n",
    "The runtime of *main()* will be equial to the maximum runtime of the tasks that it gathers together and schedules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1141fe77-5796-4af3-bed4-61103dcb45da",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def part1(n: int) -> str:\n",
    "    i = random.randint(0, 10)\n",
    "    print(f\"part1({n}) sleeping for {i} seconds...\")\n",
    "    await asyncio.sleep(i)\n",
    "\n",
    "    result = f\"result{n}-1\"\n",
    "    print(f\"Returning part1({n}) == {result}.\")\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88557d0e-2d81-4ff3-bd7f-9084cef9991d",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def part2(n: int,\n",
    "                arg: str) -> str:\n",
    "    i = random.randint(0, 10)\n",
    "    print(f\"part2({n, arg}) sleeping for {i} seconds...\")\n",
    "    await asyncio.sleep(i)\n",
    "\n",
    "    result = f\"result{n}-2 derived from {arg}\"\n",
    "    print(f\"Retruning part2{n, arg} == {result}.\")\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c95f303c-7ed1-49bb-bcd6-5ddaa9eb47e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def chain(n: int) -> None:\n",
    "    start = time.perf_counter()\n",
    "    p1 = await part1(n)\n",
    "    p2 = await part2(n, p1)\n",
    "    end = time.perf_counter() - start\n",
    "    print(f\"--> Chained result{n} => {p2} (took {end:0.2f} seconds).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7a7cda5-35db-4894-bb32-d2867ad21e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main(*args):\n",
    "    await asyncio.gather(*(chain(n) for n in args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5b8fae3-0280-499a-9043-df52e84110a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part1(1) sleeping for 4 seconds...\n",
      "part1(2) sleeping for 4 seconds...\n",
      "part1(3) sleeping for 0 seconds...\n",
      "Returning part1(3) == result3-1.\n",
      "part2((3, 'result3-1')) sleeping for 4 seconds...\n",
      "Returning part1(1) == result1-1.\n",
      "part2((1, 'result1-1')) sleeping for 7 seconds...\n",
      "Returning part1(2) == result2-1.\n",
      "part2((2, 'result2-1')) sleeping for 4 seconds...\n",
      "Retruning part2(3, 'result3-1') == result3-2 derived from result3-1.\n",
      "--> Chained result3 => result3-2 derived from result3-1 (took 4.02 seconds).\n",
      "Retruning part2(2, 'result2-1') == result2-2 derived from result2-1.\n",
      "--> Chained result2 => result2-2 derived from result2-1 (took 8.04 seconds).\n",
      "Retruning part2(1, 'result1-1') == result1-2 derived from result1-1.\n",
      "--> Chained result1 => result1-2 derived from result1-1 (took 11.04 seconds).\n",
      "Program finished in 11.04 seconds.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    random.seed(444)\n",
    "\n",
    "    args = [1, 2, 3]\n",
    "    start = time.perf_counter()\n",
    "    asyncio.run(main(*args))\n",
    "    end = time.perf_counter() - start\n",
    "\n",
    "    print(f\"Program finished in {end:0.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bcd365-610d-4dfa-a1ac-d9c3b4cf1877",
   "metadata": {},
   "source": [
    "## Using a queue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdd5cc8-9f86-460e-a476-7045b8974283",
   "metadata": {},
   "source": [
    "There is an alternative structure that can also work with async IO: a number of producers, which are not associated with each other, add items to a queue. Each producer may add multiple items to the queue at staggered, random, unannounced times. A group of consumers pull items from the queue as they show up, greedily and without waiting for any other signal.\r\n",
    "\r\n",
    "In this design, there is no chaining of any individual consumer to a producer. The consumers donâ€™t know the number of producers, or even the cumulative number of items that will be added to the queue, in advance.\r\n",
    "\r\n",
    "It takes an individual producer or consumer a variable amount of time to put and extract items from the queue, respectively. The queue serves as a throughput that can communicate with the producers and consumers without them talking to each other directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "780c819d-882e-4048-b3e7-7d89e2b8a367",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def makeitem(size: int = 5) -> str:\n",
    "    return os.urandom(size).hex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "faa2055f-1bd1-4c8f-8e2e-ea3eab4fdbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def randsleep(caller=None) -> None:\n",
    "    i = random.randint(0, 10)\n",
    "    if caller:\n",
    "        print(f\"{caller} sleeping for {i} seconds.\")\n",
    "    await asyncio.sleep(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96d854da-5bd6-4e35-b9a5-8c707161e9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def produce(name: int, q: asyncio.Queue) -> None:\n",
    "    n = random.randint(0, 10)\n",
    "    for _ in it.repeat(None, n):  # Synchronous loop for each single producer\n",
    "        await randsleep(caller=f\"Producer {name}\")\n",
    "        i = await makeitem()\n",
    "        t = time.perf_counter()\n",
    "        await q.put((i, t))\n",
    "        print(f\"Producer {name} added <{i}> to queue.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e6cd003-ffb1-42f1-a58a-dec0bcffdfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def consume(name: int, q: asyncio.Queue) -> None:\n",
    "    while True:\n",
    "        await randsleep(caller=f\"Consumer {name}\")\n",
    "        i, t = await q.get()\n",
    "        now = time.perf_counter()\n",
    "        print(f\"Consumer {name} got element <{i}>\"\n",
    "              f\" in {now-t:0.5f} seconds.\")\n",
    "        q.task_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f9c12b2-1e0c-45ea-91f7-1c9e2bbf5110",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main(nprod: int, ncon: int):\n",
    "    q = asyncio.Queue()\n",
    "    producers = [asyncio.create_task(produce(n, q)) for n in range(nprod)]\n",
    "    consumers = [asyncio.create_task(consume(n, q)) for n in range(ncon)]\n",
    "    await asyncio.gather(*producers)\n",
    "    await q.join()  # Implicitly awaits consumers, too\n",
    "    for c in consumers:\n",
    "        c.cancel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2cc4de75-f081-45b1-84e5-6bd334625525",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Producer 0 sleeping for 4 seconds.\n",
      "Consumer 0 sleeping for 4 seconds.\n",
      "Consumer 1 sleeping for 7 seconds.\n",
      "Consumer 2 sleeping for 4 seconds.\n",
      "Consumer 3 sleeping for 4 seconds.\n",
      "Consumer 4 sleeping for 8 seconds.\n",
      "Producer 0 added <72d801cf9f> to queue.\n",
      "Producer 0 sleeping for 10 seconds.\n",
      "Consumer 0 got element <72d801cf9f> in 0.00074 seconds.\n",
      "Consumer 0 sleeping for 7 seconds.\n",
      "Producer 0 added <465c9fe8e2> to queue.\n",
      "Producer 0 sleeping for 8 seconds.\n",
      "Consumer 3 got element <465c9fe8e2> in 0.00182 seconds.\n",
      "Consumer 3 sleeping for 4 seconds.\n",
      "Producer 0 added <f0305b4405> to queue.\n",
      "Producer 0 sleeping for 7 seconds.\n",
      "Consumer 2 got element <f0305b4405> in 0.00168 seconds.\n",
      "Consumer 2 sleeping for 1 seconds.\n",
      "Producer 0 added <c52bf7ce81> to queue.\n",
      "Consumer 1 got element <c52bf7ce81> in 0.00217 seconds.\n",
      "Consumer 1 sleeping for 6 seconds.\n",
      "Program completed in 29.04754 seconds.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    random.seed(444)\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"-p\", \"--nprod\", type=int, default=2)\n",
    "    parser.add_argument(\"-c\", \"--ncon\", type=int, default=5)\n",
    "    ns = parser.parse_args(args=[])\n",
    "    start = time.perf_counter()\n",
    "    asyncio.run(main(**ns.__dict__))\n",
    "    elapsed = time.perf_counter() - start\n",
    "    print(f\"Program completed in {elapsed:0.5f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d14990d-4717-4fbf-ae9b-e4a51b78f8be",
   "metadata": {},
   "source": [
    "# *Async IO*'s Roots in Generators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439e62d7-1e60-4e1f-bd08-d4ba98623bea",
   "metadata": {},
   "source": [
    "## *Async for* and Async Generators+Comprehensions\n",
    "\n",
    "Along with plain async/await, Python also enables async for to iterate over an asynchronous iterator. The purpose of an asynchronous iterator is for it to be able to call asynchronous code at each stage when it is iterated over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b1c73d8-815d-409c-bd0b-99f7832ed336",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def mygen(u: int = 10):\n",
    "    # Yield powers of 2\n",
    "    i = 0\n",
    "    while i < u:\n",
    "        yield 2 ** i\n",
    "        i += 1\n",
    "        await asyncio.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a390f90-6862-4194-9007-2c90f0ed9936",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    # This code does NOT generate concurrent execution (run two lines at the same time)\n",
    "    g = [i async for i in mygen()]\n",
    "    f = [j async for j in mygen() if not (j // 3 % 5)]\n",
    "    return g, f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "11b81940-c26d-45b3-8e7d-b5a630becdc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 2, 4, 8, 16, 32, 64, 128, 256, 512], [1, 2, 16, 32, 256, 512])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g, f = asyncio.run(main())\n",
    "g,f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58db5ad8-f46d-4ff0-8dd2-66abb9c78a84",
   "metadata": {},
   "source": [
    "# Asynchronous Requests code\n",
    "\n",
    "Code that builds a web-scraping URL collector following the next steps:\n",
    "1. Read a sequence of URLs from a local file, urls.txt.\n",
    "2. Send GET requests for the URLs and decode the resulting content. If this fails, stop there for a URL.\n",
    "3. Search for the URLs within href tags in the HTML of the responses.\n",
    "4. Write the results to foundurls.txt.\n",
    "5. Do all of the above as asynchronously and concurrently as possible. (Use aiohttp for the requests, and aiofiles for the file-appends. These are two primary examples of IO that are well-suited for the async IO model.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5fecf123-1755-4671-a7aa-d17d913c0893",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import logging\n",
    "import re\n",
    "import sys\n",
    "import urllib.error\n",
    "import urllib.parse\n",
    "import aiofiles\n",
    "import aiohttp\n",
    "\n",
    "from typing import IO\n",
    "from aiohttp import ClientSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e5c6584c-bebb-4d06-9a31-a0b5e947461e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format = \"%(asctime)s %(levelname)s:%(name)s: %(message)s\",\n",
    "                    level = logging.DEBUG,\n",
    "                    datefmt = \"%H:%H:%S\",\n",
    "                    stream = sys.stderr,)\n",
    "\n",
    "logger = logging.getLogger(\"areq\")\n",
    "logging.getLogger(\"chardet.charsetprober\").disabled = True\n",
    "\n",
    "HREF_RE = re.compile(r'href=\"(.*?)\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c8aaef30-9404-4acf-ba5e-468621418537",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def fetch_html(url: str,\n",
    "                     session: ClientSession,\n",
    "                     **kwargs) -> str:\n",
    "\n",
    "    # GET request wrapper to fetch page HTML\n",
    "    resp = await session.request(method = \"GET\",\n",
    "                                 url = url,\n",
    "                                 **kwargs)\n",
    "    resp.raise_for_status()\n",
    "\n",
    "    logger.info(f\"Got response [{resp.status}] for URL: {url}\")\n",
    "    html = await resp.text()\n",
    "\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "84111594-2c44-494c-934f-769734e2c4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def parse(url: str,\n",
    "                session: ClientSession,\n",
    "                **kwargs) -> set:\n",
    "\n",
    "    # Find HREFs in the HTML of the url\n",
    "    found = set()\n",
    "    try:\n",
    "        html = await fetch_html(url = url,\n",
    "                                session = session,\n",
    "                                **kwargs)\n",
    "    except(aiohttp.ClientError,\n",
    "           aiohttp.http_exceptions.HttpProcessingError,) as e:\n",
    "        logger.error(f\"aiohttp exception for {url} [{getattr(e, 'status', None)}]: {getattr(e, 'message', None)}\")\n",
    "\n",
    "        return found\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.exception(f\"Non-aiohttp exception occured: {getattr(e, '__dict__', {})}\")\n",
    "        return found\n",
    "\n",
    "    else:\n",
    "        for link in HREF_RE.findall(html):\n",
    "            try:\n",
    "                abslink = urllib.parse.urljoin(url, link)\n",
    "            \n",
    "            except(urllib.error.URLError, ValueError):\n",
    "                logger.exception(f\"Error parsing URL: {link}\")\n",
    "                pass\n",
    "\n",
    "            else:\n",
    "                found.add(abslink)\n",
    "\n",
    "        logger.info(f\"Found {len(found)} links for {url}\")\n",
    "        \n",
    "        return found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8ceec678-9af6-4455-bf29-234399f66f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def write_one(file: IO,\n",
    "                    url: str,\n",
    "                    **kwargs) -> None:\n",
    "\n",
    "    # Write the found HREFs from url to file\n",
    "    res = await parse(url = url,\n",
    "                      **kwargs)\n",
    "\n",
    "    if not res:\n",
    "        return None\n",
    "    \n",
    "    async with aiofiles.open(file, \"a\") as f:\n",
    "        for p in res:\n",
    "            await f.write(f\"{url}\\t{p}\\n\")\n",
    "        logger.info(f\"Wrote results for source URL: {url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1758bc32-9695-4a62-9659-19f6b82bff51",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def bulk_crawl_and_write(file: IO,\n",
    "                               urls: set,\n",
    "                               **kwargs) -> None:\n",
    "\n",
    "    # Crawl and write concurrently to file for multiple urls\n",
    "    async with ClientSession() as session:\n",
    "        tasks = []\n",
    "        for url in urls:\n",
    "            tasks.append(write_one(file = file,\n",
    "                                   url = url,\n",
    "                                   session = session,\n",
    "                                   **kwargs))\n",
    "            await asyncio.gather(*tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "997eee15-ebe5-4a5c-ae4f-5da449cdb64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:11:13 INFO:areq: Got response [200] for URL: https://regex101.com/\n",
      "11:11:13 INFO:areq: Found 76 links for https://regex101.com/\n",
      "11:11:13 INFO:areq: Wrote results for source URL: https://regex101.com/\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cannot reuse already awaited coroutine",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(outpath, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m outfile:\n\u001b[0;32m     13\u001b[0m     outfile\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource_url\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mparsed_url\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m asyncio\u001b[38;5;241m.\u001b[39mrun(bulk_crawl_and_write(file \u001b[38;5;241m=\u001b[39m outpath,\n\u001b[0;32m     16\u001b[0m                                  urls \u001b[38;5;241m=\u001b[39m urls))\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\nest_asyncio.py:35\u001b[0m, in \u001b[0;36m_patch_asyncio.<locals>.run\u001b[1;34m(main, debug)\u001b[0m\n\u001b[0;32m     33\u001b[0m task \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(main)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mrun_until_complete(task)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task\u001b[38;5;241m.\u001b[39mdone():\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\nest_asyncio.py:90\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[1;34m(self, future)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m     89\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvent loop stopped before Future completed.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39mresult()\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\asyncio\\futures.py:203\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__log_traceback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 203\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception_tb)\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\asyncio\\tasks.py:267\u001b[0m, in \u001b[0;36mTask.__step\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    264\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    265\u001b[0m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[0;32m    266\u001b[0m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    268\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    269\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39mthrow(exc)\n",
      "Cell \u001b[1;32mIn[45], line 13\u001b[0m, in \u001b[0;36mbulk_crawl_and_write\u001b[1;34m(file, urls, **kwargs)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m url \u001b[38;5;129;01min\u001b[39;00m urls:\n\u001b[0;32m      9\u001b[0m     tasks\u001b[38;5;241m.\u001b[39mappend(write_one(file \u001b[38;5;241m=\u001b[39m file,\n\u001b[0;32m     10\u001b[0m                            url \u001b[38;5;241m=\u001b[39m url,\n\u001b[0;32m     11\u001b[0m                            session \u001b[38;5;241m=\u001b[39m session,\n\u001b[0;32m     12\u001b[0m                            \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[1;32m---> 13\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39mtasks)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\asyncio\\tasks.py:339\u001b[0m, in \u001b[0;36mTask.__wakeup\u001b[1;34m(self, future)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 339\u001b[0m         future\u001b[38;5;241m.\u001b[39mresult()\n\u001b[0;32m    340\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    341\u001b[0m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[0;32m    342\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__step(exc)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\asyncio\\tasks.py:267\u001b[0m, in \u001b[0;36mTask.__step\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    264\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    265\u001b[0m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[0;32m    266\u001b[0m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    268\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    269\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39mthrow(exc)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: cannot reuse already awaited coroutine"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:11:13 ERROR:areq: aiohttp exception for https://www.bloomberg.com/markets/economics [None]: None\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import pathlib\n",
    "    import sys\n",
    "\n",
    "    assert sys.version_info >= (3,7)\n",
    "    # here = pathlib.Path(__file__).parent\n",
    "\n",
    "    with open(\"urls.txt\") as infile:\n",
    "        urls = set(map(str.strip, infile))\n",
    "\n",
    "    outpath = \"foundurls.txt\"\n",
    "    with open(outpath, \"w\") as outfile:\n",
    "        outfile.write(\"source_url\\tparsed_url\\n\")\n",
    "\n",
    "    asyncio.run(bulk_crawl_and_write(file = outpath,\n",
    "                                     urls = urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c30b5f8-d6a6-4c24-ab08-b6386f247b25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
